{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading S3 bucket into SageMaker Studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from io import StringIO\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "s3_client = boto3.client(\"s3\")\n",
    "\n",
    "BUCKET='ads508projectbucket'\n",
    "\n",
    "# For Country_and_Subscriber_df\n",
    "Country_and_Subscriber_Key='Aggregated_Metrics_By_Country_And_Subscriber_Status.csv'\n",
    "Country_and_Subscriber_response = s3_client.get_object(Bucket=BUCKET, Key=Country_and_Subscriber_Key)\n",
    "Country_and_Subscriber_df = pd.read_csv(Country_and_Subscriber_response.get(\"Body\"))\n",
    "\n",
    "# For Video_df\n",
    "Video_Key='Aggregated_Metrics_By_Video.csv'\n",
    "Video_response = s3_client.get_object(Bucket=BUCKET, Key=Video_Key)\n",
    "Video_df = pd.read_csv(Video_response.get(\"Body\"))\n",
    "\n",
    "# For Comments_df\n",
    "Comments_Key='All_Comments_Final.csv'\n",
    "Comments_response = s3_client.get_object(Bucket=BUCKET, Key=Comments_Key)\n",
    "Comments_df = pd.read_csv(Comments_response.get(\"Body\"))\n",
    "\n",
    "# For Performance_df\n",
    "Performance_Key='Video_Performance_Over_Time.csv'\n",
    "Performance_response = s3_client.get_object(Bucket=BUCKET, Key=Performance_Key)\n",
    "Performance_df = pd.read_csv(Performance_response.get(\"Body\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming Data for Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this data set, we want to find the max reply count and the max like count for a comment in each video. To do this, we will group by unique Video ID and find the max. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Comments_altered = Comments_df[['VidId', 'Reply_Count', 'Like_Count']]\n",
    "grouped_comments = Comments_altered.groupby(by = 'VidId', as_index = False).max()\n",
    "transformed_comments = grouped_comments[['VidId', 'Reply_Count', 'Like_Count']]\n",
    "transformed_comments.rename(columns = {'Reply_Count': 'Reply_Comment_Count', 'Like_Count': 'Like_Comment_Count', 'VidId': 'External Video ID'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>External Video ID</th>\n",
       "      <th>Reply_Comment_Count</th>\n",
       "      <th>Like_Comment_Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3d1NctSv0c</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-ONQ628CXKQ</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-kX2b6TF_9k</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-pdXWmj9xxU</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-zbLpoJVBMI</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  External Video ID  Reply_Comment_Count  Like_Comment_Count\n",
       "0       -3d1NctSv0c                    3                   5\n",
       "1       -ONQ628CXKQ                    5                  31\n",
       "2       -kX2b6TF_9k                    2                   2\n",
       "3       -pdXWmj9xxU                    3                   9\n",
       "4       -zbLpoJVBMI                    4                  17"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_comments.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the only useful information needed from this data set, so we will keep this as is and move onto the next transformation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Country_and_Subscriber_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saw from our EDA that the United States and Inda were the two countries which watched the most of Ken Jee's channel. Knowing this, we can look at the percentage of views from the USA and IN to help us with our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pulling important rows\n",
    "transformed_country = Country_and_Subscriber_df[['External Video ID', 'Country Code', 'Views']]\n",
    "\n",
    "# creating empty df\n",
    "rangeRow = len(transformed_country['External Video ID'].unique())\n",
    "test = pd.DataFrame(index = range(rangeRow), columns=['External Video ID','USA_views', 'IN_views','other_countries_views','total_views'], dtype = object)\n",
    "\n",
    "# calc. values into empty df\n",
    "testRow = 0 \n",
    "for j in transformed_country['External Video ID'].unique():\n",
    "    video_split = transformed_country[transformed_country['External Video ID'] == j]\n",
    "    test.loc[testRow, 'External Video ID'] = j\n",
    "    world_views = 0\n",
    "    other_views = 0\n",
    "    USA_views = 0\n",
    "    IN_views = 0\n",
    "    for i in range(len(video_split)):\n",
    "        if video_split.iloc[i, 1] == 'US':\n",
    "            USA_views = video_split.iloc[i, 2]\n",
    "        elif video_split.iloc[i, 1] == 'IN':\n",
    "            IN_views = video_split.iloc[i, 2]\n",
    "        else:\n",
    "            other_views = video_split.iloc[i, 2]\n",
    "        world_views = world_views + other_views  \n",
    "    test.loc[testRow,'USA_views'] = USA_views\n",
    "    test.loc[testRow, 'IN_views'] = IN_views\n",
    "    test.loc[testRow, 'other_countries_views'] = world_views\n",
    "    test.loc[testRow, 'total_views'] = USA_views + IN_views + world_views\n",
    "    testRow = testRow + 1\n",
    "\n",
    "# finalizing data frame by finding percentages and removing unneeded columns\n",
    "transformed_country = test\n",
    "transformed_country['USA%_veiws'] = (transformed_country['USA_views'] / transformed_country['total_views']) * 100\n",
    "transformed_country['IN%_views'] = (transformed_country['IN_views'] / transformed_country['total_views']) * 100\n",
    "transformed_country['Other_country%_ views'] = (transformed_country['other_countries_views'] / transformed_country['total_views']) * 100\n",
    "transformed_country.drop(['USA_views', 'IN_views', 'other_countries_views', 'total_views'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>External Video ID</th>\n",
       "      <th>USA%_veiws</th>\n",
       "      <th>IN%_views</th>\n",
       "      <th>Other_country%_ views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OtqQYqRNDGI</td>\n",
       "      <td>15.2449</td>\n",
       "      <td>23.9834</td>\n",
       "      <td>60.7718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>_0rHU6qAQe0</td>\n",
       "      <td>16.761</td>\n",
       "      <td>12.2985</td>\n",
       "      <td>70.9405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4CpmB4TR2C4</td>\n",
       "      <td>6.87174</td>\n",
       "      <td>17.9558</td>\n",
       "      <td>75.1724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3ysXGYjvbSU</td>\n",
       "      <td>21.7565</td>\n",
       "      <td>5.78842</td>\n",
       "      <td>72.4551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s1gD35Z4eUc</td>\n",
       "      <td>11.1441</td>\n",
       "      <td>6.63136</td>\n",
       "      <td>82.2246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  External Video ID USA%_veiws IN%_views Other_country%_ views\n",
       "0       OtqQYqRNDGI    15.2449   23.9834               60.7718\n",
       "1       _0rHU6qAQe0     16.761   12.2985               70.9405\n",
       "2       4CpmB4TR2C4    6.87174   17.9558               75.1724\n",
       "3       3ysXGYjvbSU    21.7565   5.78842               72.4551\n",
       "4       s1gD35Z4eUc    11.1441   6.63136               82.2246"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_country.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this data frame, we need to remove the first row due to it giving column values and not row values. Then, we are going to change the video publish time to day of the week. We will also create a boolean feature which states if 'Data Science' appears in the title of the video or not. We also need to convert the average view duration to seconds rather than minute second format. Lastly, we will remove the total likes and dislikes column and replace it with a 'like_dislike_ratio' column. From this data frame, we want to attempt to predict the 'Your estimated revenue (USD)' feature. This feature tells us the estimated revenue of the video and will inform the video creator if they are being paid less or more than predicted by our model from historical data. To remove any features that will bias our results, we also want to remove 'RPM' and 'CPM' for giving away monetary information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# removing first row\n",
    "transform_video = Video_df.iloc[1:,:]\n",
    "transform_video.reset_index(inplace = True, drop = True)\n",
    "\n",
    "# changing 'Video publish time' to day of the week\n",
    "transform_video['Video pub­lish time'] = pd.to_datetime(transform_video['Video pub­lish time'])\n",
    "transform_video['Video_Day_Published'] = transform_video['Video pub­lish time'].dt.day_name()\n",
    "\n",
    "# we now want to create n-1 dummy features to replace 'Video_Day_Published'\n",
    "dummy_day = pd.get_dummies(transform_video['Video_Day_Published'], drop_first = True)\n",
    "transform_video = pd.concat([transform_video, dummy_day], axis = 1)\n",
    "\n",
    "# next, we will created a boolean feature which specifies if 'Data Science' is in the title or not\n",
    "test = range(len(transform_video['Video title']))\n",
    "test = pd.DataFrame(test)\n",
    "row = 0\n",
    "for i in transform_video['Video title']:\n",
    "    find_data = i.count('Data')\n",
    "    find_science = i.count('Science')\n",
    "    if find_data != 0 and find_science != 0:\n",
    "        test.iloc[row, 0] = 1\n",
    "    else:\n",
    "        test.iloc[row, 0] = 0\n",
    "    row = row + 1\n",
    "\n",
    "test.rename(columns = {0: 'DataScience?'}, inplace = True)\n",
    "transform_video = pd.concat([transform_video, test], axis = 1)\n",
    "\n",
    "# changing average view duration to seconds format\n",
    "test = range(len(transform_video['Av­er­age view dur­a­tion']))\n",
    "test = pd.DataFrame(test)\n",
    "row = 0\n",
    "for i in transform_video['Av­er­age view dur­a­tion']:\n",
    "    time = i.split(':')\n",
    "    hour = int(time[0])\n",
    "    hour_to_sec = hour * 3600\n",
    "    min = int(time[1])\n",
    "    min_to_sec = min * 60\n",
    "    sec = int(time[2])\n",
    "    total_time = hour_to_sec + min_to_sec + sec\n",
    "    test.loc[row, 0] = total_time\n",
    "    row = row + 1\n",
    "\n",
    "test.rename(columns = {0: 'Average_view_duration_(s)'}, inplace = True)\n",
    "transform_video = pd.concat([transform_video, test], axis = 1)\n",
    "\n",
    "# finding the like to dislike ratio\n",
    "transform_video['Like_Dislike_Ratio'] = round(transform_video['Likes'] / transform_video['Dis­likes'], 2)\n",
    "row = 0\n",
    "for i in transform_video['Like_Dislike_Ratio']:\n",
    "    if i > 10000:\n",
    "        transform_video.loc[row,'Like_Dislike_Ratio'] = transform_video.loc[row,'Likes'] \n",
    "    row = row + 1\n",
    "\n",
    "# Now, we will remove features which are not needed\n",
    "transform_video.drop(['Video title', 'Video pub­lish time', 'RPM (USD)', 'CPM (USD)', 'Video_Day_Published', 'Av­er­age view dur­a­tion', 'Likes', 'Dis­likes', 'Sub­scribers lost', 'Sub­scribers gained'], axis = 1, inplace = True)\n",
    "transform_video.rename(columns = {'Video': 'External Video ID'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>External Video ID</th>\n",
       "      <th>Com­ments ad­ded</th>\n",
       "      <th>Shares</th>\n",
       "      <th>Av­er­age per­cent­age viewed (%)</th>\n",
       "      <th>Views</th>\n",
       "      <th>Watch time (hours)</th>\n",
       "      <th>Sub­scribers</th>\n",
       "      <th>Your es­tim­ated rev­en­ue (USD)</th>\n",
       "      <th>Im­pres­sions</th>\n",
       "      <th>Im­pres­sions click-through rate (%)</th>\n",
       "      <th>Monday</th>\n",
       "      <th>Saturday</th>\n",
       "      <th>Sunday</th>\n",
       "      <th>Thursday</th>\n",
       "      <th>Tuesday</th>\n",
       "      <th>Wednesday</th>\n",
       "      <th>DataScience?</th>\n",
       "      <th>Average_view_duration_(s)</th>\n",
       "      <th>Like_Dislike_Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4OZip0cgOho</td>\n",
       "      <td>907</td>\n",
       "      <td>9583</td>\n",
       "      <td>36.65</td>\n",
       "      <td>1253559</td>\n",
       "      <td>65850.7042</td>\n",
       "      <td>46453</td>\n",
       "      <td>7959.533</td>\n",
       "      <td>26498799</td>\n",
       "      <td>3.14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>189</td>\n",
       "      <td>49.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>78LjdAAw0wA</td>\n",
       "      <td>412</td>\n",
       "      <td>4</td>\n",
       "      <td>6.26</td>\n",
       "      <td>2291</td>\n",
       "      <td>200.2966</td>\n",
       "      <td>-3</td>\n",
       "      <td>6.113</td>\n",
       "      <td>188318</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>314</td>\n",
       "      <td>32.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hO_YKK_0Qck</td>\n",
       "      <td>402</td>\n",
       "      <td>152</td>\n",
       "      <td>15.12</td>\n",
       "      <td>21350</td>\n",
       "      <td>3687.3387</td>\n",
       "      <td>189</td>\n",
       "      <td>202.963</td>\n",
       "      <td>442334</td>\n",
       "      <td>2.53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>621</td>\n",
       "      <td>58.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>uXLnbdHMf8w</td>\n",
       "      <td>375</td>\n",
       "      <td>367</td>\n",
       "      <td>33.41</td>\n",
       "      <td>49564</td>\n",
       "      <td>2148.3110</td>\n",
       "      <td>1917</td>\n",
       "      <td>155.779</td>\n",
       "      <td>521185</td>\n",
       "      <td>4.01</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>119.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Xgg7dIKys9E</td>\n",
       "      <td>329</td>\n",
       "      <td>118</td>\n",
       "      <td>9.55</td>\n",
       "      <td>13429</td>\n",
       "      <td>1034.3945</td>\n",
       "      <td>150</td>\n",
       "      <td>39.920</td>\n",
       "      <td>210876</td>\n",
       "      <td>3.38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>277</td>\n",
       "      <td>39.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  External Video ID  Com­ments ad­ded  Shares  \\\n",
       "0       4OZip0cgOho               907    9583   \n",
       "1       78LjdAAw0wA               412       4   \n",
       "2       hO_YKK_0Qck               402     152   \n",
       "3       uXLnbdHMf8w               375     367   \n",
       "4       Xgg7dIKys9E               329     118   \n",
       "\n",
       "   Av­er­age per­cent­age viewed (%)    Views  Watch time (hours)  \\\n",
       "0                              36.65  1253559          65850.7042   \n",
       "1                               6.26     2291            200.2966   \n",
       "2                              15.12    21350           3687.3387   \n",
       "3                              33.41    49564           2148.3110   \n",
       "4                               9.55    13429           1034.3945   \n",
       "\n",
       "   Sub­scribers  Your es­tim­ated rev­en­ue (USD)  Im­pres­sions  \\\n",
       "0         46453                          7959.533       26498799   \n",
       "1            -3                             6.113         188318   \n",
       "2           189                           202.963         442334   \n",
       "3          1917                           155.779         521185   \n",
       "4           150                            39.920         210876   \n",
       "\n",
       "   Im­pres­sions click-through rate (%)  Monday  Saturday  Sunday  Thursday  \\\n",
       "0                                  3.14       0         0       0         0   \n",
       "1                                  0.72       0         0       0         1   \n",
       "2                                  2.53       0         0       0         1   \n",
       "3                                  4.01       0         1       0         0   \n",
       "4                                  3.38       0         0       0         0   \n",
       "\n",
       "   Tuesday  Wednesday  DataScience?  Average_view_duration_(s)  \\\n",
       "0        0          0             1                        189   \n",
       "1        0          0             0                        314   \n",
       "2        0          0             0                        621   \n",
       "3        0          0             1                        156   \n",
       "4        0          1             0                        277   \n",
       "\n",
       "   Like_Dislike_Ratio  \n",
       "0               49.79  \n",
       "1               32.50  \n",
       "2               58.73  \n",
       "3              119.18  \n",
       "4               39.33  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform_video.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this data frame, we can use the video length feature to help with our predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Performance_altered = Performance_df[['External Video ID', 'Video Length']]\n",
    "transformed_performance = Performance_altered.groupby(by = 'External Video ID').max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video Length</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>External Video ID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-3d1NctSv0c</th>\n",
       "      <td>3413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-ONQ628CXKQ</th>\n",
       "      <td>964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-kX2b6TF_9k</th>\n",
       "      <td>656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-pdXWmj9xxU</th>\n",
       "      <td>866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-zbLpoJVBMI</th>\n",
       "      <td>368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Video Length\n",
       "External Video ID              \n",
       "-3d1NctSv0c                3413\n",
       "-ONQ628CXKQ                 964\n",
       "-kX2b6TF_9k                 656\n",
       "-pdXWmj9xxU                 866\n",
       "-zbLpoJVBMI                 368"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_performance.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the only new information we can retrieve from this data set due to having to aggregate based off video ID."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging Data into one Data Frame, Normalizing, Splitting Data, and Writing to S3 Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'HC5GT893PGXG0A4X',\n",
       "  'HostId': 'lCEwK7qlEU9lS5HhvVuBbHYfm8LGAa7kZ8qjrU9nHabKFgMKYt2rSI6WbfhGO91WSZZ0eDaQYOs=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': 'lCEwK7qlEU9lS5HhvVuBbHYfm8LGAa7kZ8qjrU9nHabKFgMKYt2rSI6WbfhGO91WSZZ0eDaQYOs=',\n",
       "   'x-amz-request-id': 'HC5GT893PGXG0A4X',\n",
       "   'date': 'Mon, 28 Mar 2022 21:23:03 GMT',\n",
       "   'etag': '\"f6b7b796698b2215c03e1ed712476874\"',\n",
       "   'server': 'AmazonS3',\n",
       "   'content-length': '0'},\n",
       "  'RetryAttempts': 0},\n",
       " 'ETag': '\"f6b7b796698b2215c03e1ed712476874\"'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first, we will merge the 4 data sets into one\n",
    "df_merge = pd.merge(transformed_performance, transformed_country, on = 'External Video ID')\n",
    "df_merge2 = pd.merge(transform_video, transformed_comments, on = 'External Video ID')\n",
    "df_merge_final = pd.merge(df_merge, df_merge2, on = 'External Video ID')\n",
    "\n",
    "# dropping video id\n",
    "df_merge_final.drop(['External Video ID'], axis  = 1, inplace = True)\n",
    "\n",
    "# The last step is to normalize our data due to having different units\n",
    "normalized_df = df_merge_final[['Video Length', 'USA%_veiws', 'IN%_views', 'Other_country%_ views', 'Com­ments ad­ded', 'Shares', 'Av­er­age per­cent­age viewed (%)', \n",
    "                                'Views', 'Watch time (hours)', 'Sub­scribers', 'Im­pres­sions', 'Im­pres­sions click-through rate (%)', 'Average_view_duration_(s)', \n",
    "                                'Like_Dislike_Ratio', 'Reply_Comment_Count', 'Like_Comment_Count']]\n",
    "not_normalized_df = df_merge_final[['Monday', 'Saturday', 'Sunday', 'Thursday', 'Tuesday', 'Wednesday', 'DataScience?', 'Your es­tim­ated rev­en­ue (USD)']]\n",
    "normalized_df = (normalized_df-normalized_df.mean())/normalized_df.std()\n",
    "final_df = pd.concat([normalized_df, not_normalized_df], axis = 1)\n",
    "\n",
    "# Splitting data\n",
    "training, rem = train_test_split(final_df, train_size=0.8, random_state=42)\n",
    "valid, test = train_test_split(rem, train_size=0.5, random_state=42)\n",
    "training = pd.concat([training, training, training], axis = 0)\n",
    "\n",
    "# uploading training to S3 bucket\n",
    "csv_buffer = StringIO()\n",
    "training.to_csv(csv_buffer)\n",
    "s3_resource = boto3.resource('s3')\n",
    "s3_resource.Object(BUCKET, 'training_df.csv').put(Body = csv_buffer.getvalue())\n",
    "\n",
    "# uploading validation to S3 bucket\n",
    "csv_buffer = StringIO()\n",
    "valid.to_csv(csv_buffer)\n",
    "s3_resource = boto3.resource('s3')\n",
    "s3_resource.Object(BUCKET, 'validation_df.csv').put(Body = csv_buffer.getvalue())\n",
    "\n",
    "# uploading testing to S3 bucket\n",
    "csv_buffer = StringIO()\n",
    "test.to_csv(csv_buffer)\n",
    "s3_resource = boto3.resource('s3')\n",
    "s3_resource.Object(BUCKET, 'testing_df.csv').put(Body = csv_buffer.getvalue())"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
