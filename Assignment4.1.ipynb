{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading S3 bucket into SageMaker Studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "s3_client = boto3.client(\"s3\")\n",
    "\n",
    "BUCKET='ads508projectbucket'\n",
    "\n",
    "# For Country_and_Subscriber_df\n",
    "Country_and_Subscriber_Key='Aggregated_Metrics_By_Country_And_Subscriber_Status.csv'\n",
    "Country_and_Subscriber_response = s3_client.get_object(Bucket=BUCKET, Key=Country_and_Subscriber_Key)\n",
    "Country_and_Subscriber_df = pd.read_csv(Country_and_Subscriber_response.get(\"Body\"))\n",
    "\n",
    "# For Video_df\n",
    "Video_Key='Aggregated_Metrics_By_Video.csv'\n",
    "Video_response = s3_client.get_object(Bucket=BUCKET, Key=Video_Key)\n",
    "Video_df = pd.read_csv(Video_response.get(\"Body\"))\n",
    "\n",
    "# For Comments_df\n",
    "Comments_Key='All_Comments_Final.csv'\n",
    "Comments_response = s3_client.get_object(Bucket=BUCKET, Key=Comments_Key)\n",
    "Comments_df = pd.read_csv(Comments_response.get(\"Body\"))\n",
    "\n",
    "# For Performance_df\n",
    "Performance_Key='Video_Performance_Over_Time.csv'\n",
    "Performance_response = s3_client.get_object(Bucket=BUCKET, Key=Performance_Key)\n",
    "Performance_df = pd.read_csv(Performance_response.get(\"Body\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming Data for Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this data set, we want to find the max reply count and the max like count for a comment in each video. To do this, we will group by unique Video ID and find the max. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VidId</th>\n",
       "      <th>Reply_Comment_Count</th>\n",
       "      <th>Like_Comment_Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3d1NctSv0c</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-ONQ628CXKQ</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-kX2b6TF_9k</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-pdXWmj9xxU</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-zbLpoJVBMI</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         VidId  Reply_Comment_Count  Like_Comment_Count\n",
       "0  -3d1NctSv0c                    3                   5\n",
       "1  -ONQ628CXKQ                    5                  31\n",
       "2  -kX2b6TF_9k                    2                   2\n",
       "3  -pdXWmj9xxU                    3                   9\n",
       "4  -zbLpoJVBMI                    4                  17"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Comments_altered = Comments_df[['VidId', 'Reply_Count', 'Like_Count']]\n",
    "grouped_comments = Comments_altered.groupby(by = 'VidId', as_index = False).max()\n",
    "transformed_comments = grouped_comments[['VidId', 'Reply_Count', 'Like_Count']]\n",
    "transformed_comments.rename(columns = {'Reply_Count': 'Reply_Comment_Count', 'Like_Count': 'Like_Comment_Count'}, inplace = True)\n",
    "transformed_comments.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the only useful information needed from this data set, so we will keep this as is and move onto the next transformation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Country_and_Subscriber_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this data frame, we need to remove the first row due to it giving column values and not row values. Then, we are going to change the video publish time to day of the week. We will also create a boolean feature which states if 'Data Science' appears in the title of the video or not. We also need to convert the average view duration to seconds rather than minute second format. Lastly, we will remove the total likes and dislikes column and replace it with a 'like_dislike_ratio' column. From this data frame, we want to attempt to predict the 'Your estimated revenue (USD)' feature. This feature tells us the estimated revenue of the video and will inform the video creator if they are being paid less or more than predicted by our model from historical data. To remove any features that will bias our results, we also want to remove 'RPM' and 'CPM' for giving away monetary information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# removing first row\n",
    "transform_video = Video_df.iloc[1:,:]\n",
    "transform_video.reset_index(inplace = True, drop = True)\n",
    "\n",
    "# changing 'Video publish time' to day of the week\n",
    "transform_video['Video pub­lish time'] = pd.to_datetime(transform_video['Video pub­lish time'])\n",
    "transform_video['Video_Day_Published'] = transform_video['Video pub­lish time'].dt.day_name()\n",
    "\n",
    "# we now want to create n-1 dummy features to replace 'Video_Day_Published'\n",
    "dummy_day = pd.get_dummies(transform_video['Video_Day_Published'], drop_first = True)\n",
    "transform_video = pd.concat([transform_video, dummy_day], axis = 1)\n",
    "\n",
    "# next, we will created a boolean feature which specifies if 'Data Science' is in the title or not\n",
    "test = range(len(transform_video['Video title']))\n",
    "test = pd.DataFrame(test)\n",
    "row = 0\n",
    "for i in transform_video['Video title']:\n",
    "    find_data = i.count('Data')\n",
    "    find_science = i.count('Science')\n",
    "    if find_data != 0 and find_science != 0:\n",
    "        test.iloc[row, 0] = 1\n",
    "    else:\n",
    "        test.iloc[row, 0] = 0\n",
    "    row = row + 1\n",
    "\n",
    "test.rename(columns = {0: 'DateScience?'}, inplace = True)\n",
    "transform_video = pd.concat([transform_video, test], axis = 1)\n",
    "\n",
    "# changing average view duration to seconds format\n",
    "test = range(len(transform_video['Av­er­age view dur­a­tion']))\n",
    "test = pd.DataFrame(test)\n",
    "row = 0\n",
    "for i in transform_video['Av­er­age view dur­a­tion']:\n",
    "    time = i.split(':')\n",
    "    hour = int(time[0])\n",
    "    hour_to_sec = hour * 3600\n",
    "    min = int(time[1])\n",
    "    min_to_sec = min * 60\n",
    "    sec = int(time[2])\n",
    "    total_time = hour_to_sec + min_to_sec + sec\n",
    "    test.loc[row, 0] = total_time\n",
    "    row = row + 1\n",
    "\n",
    "test.rename(columns = {0: 'Average_view_duration_(s)'}, inplace = True)\n",
    "transform_video = pd.concat([transform_video, test], axis = 1)\n",
    "\n",
    "# finding the like to dislike ratio\n",
    "transform_video['Like_Dislike_Ratio'] = round(transform_video['Likes'] / transform_video['Dis­likes'], 2)\n",
    "row = 0\n",
    "for i in transform_video['Like_Dislike_Ratio']:\n",
    "    if i > 10000:\n",
    "        transform_video.loc[row,'Like_Dislike_Ratio'] = transform_video.loc[row,'Likes'] \n",
    "    row = row + 1\n",
    "\n",
    "# Now, we will remove features which are not needed\n",
    "transform_video.drop(['Video title', 'Video pub­lish time', 'RPM (USD)', 'CPM (USD)', 'Video_Day_Published', 'Av­er­age view dur­a­tion', 'Likes', 'Dis­likes'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video</th>\n",
       "      <th>Com­ments ad­ded</th>\n",
       "      <th>Shares</th>\n",
       "      <th>Sub­scribers lost</th>\n",
       "      <th>Sub­scribers gained</th>\n",
       "      <th>Av­er­age per­cent­age viewed (%)</th>\n",
       "      <th>Views</th>\n",
       "      <th>Watch time (hours)</th>\n",
       "      <th>Sub­scribers</th>\n",
       "      <th>Your es­tim­ated rev­en­ue (USD)</th>\n",
       "      <th>...</th>\n",
       "      <th>Im­pres­sions click-through rate (%)</th>\n",
       "      <th>Monday</th>\n",
       "      <th>Saturday</th>\n",
       "      <th>Sunday</th>\n",
       "      <th>Thursday</th>\n",
       "      <th>Tuesday</th>\n",
       "      <th>Wednesday</th>\n",
       "      <th>DateScience?</th>\n",
       "      <th>Average_view_duration_(s)</th>\n",
       "      <th>Like_Dislike_Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4OZip0cgOho</td>\n",
       "      <td>907</td>\n",
       "      <td>9583</td>\n",
       "      <td>451</td>\n",
       "      <td>46904</td>\n",
       "      <td>36.65</td>\n",
       "      <td>1253559</td>\n",
       "      <td>65850.7042</td>\n",
       "      <td>46453</td>\n",
       "      <td>7959.533</td>\n",
       "      <td>...</td>\n",
       "      <td>3.14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>189</td>\n",
       "      <td>49.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>78LjdAAw0wA</td>\n",
       "      <td>412</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>6.26</td>\n",
       "      <td>2291</td>\n",
       "      <td>200.2966</td>\n",
       "      <td>-3</td>\n",
       "      <td>6.113</td>\n",
       "      <td>...</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>314</td>\n",
       "      <td>32.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hO_YKK_0Qck</td>\n",
       "      <td>402</td>\n",
       "      <td>152</td>\n",
       "      <td>9</td>\n",
       "      <td>198</td>\n",
       "      <td>15.12</td>\n",
       "      <td>21350</td>\n",
       "      <td>3687.3387</td>\n",
       "      <td>189</td>\n",
       "      <td>202.963</td>\n",
       "      <td>...</td>\n",
       "      <td>2.53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>621</td>\n",
       "      <td>58.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>uXLnbdHMf8w</td>\n",
       "      <td>375</td>\n",
       "      <td>367</td>\n",
       "      <td>40</td>\n",
       "      <td>1957</td>\n",
       "      <td>33.41</td>\n",
       "      <td>49564</td>\n",
       "      <td>2148.3110</td>\n",
       "      <td>1917</td>\n",
       "      <td>155.779</td>\n",
       "      <td>...</td>\n",
       "      <td>4.01</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>119.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Xgg7dIKys9E</td>\n",
       "      <td>329</td>\n",
       "      <td>118</td>\n",
       "      <td>11</td>\n",
       "      <td>161</td>\n",
       "      <td>9.55</td>\n",
       "      <td>13429</td>\n",
       "      <td>1034.3945</td>\n",
       "      <td>150</td>\n",
       "      <td>39.920</td>\n",
       "      <td>...</td>\n",
       "      <td>3.38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>277</td>\n",
       "      <td>39.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Video  Com­ments ad­ded  Shares  Sub­scribers lost  \\\n",
       "0  4OZip0cgOho               907    9583                451   \n",
       "1  78LjdAAw0wA               412       4                 15   \n",
       "2  hO_YKK_0Qck               402     152                  9   \n",
       "3  uXLnbdHMf8w               375     367                 40   \n",
       "4  Xgg7dIKys9E               329     118                 11   \n",
       "\n",
       "   Sub­scribers gained  Av­er­age per­cent­age viewed (%)    Views  \\\n",
       "0                46904                              36.65  1253559   \n",
       "1                   12                               6.26     2291   \n",
       "2                  198                              15.12    21350   \n",
       "3                 1957                              33.41    49564   \n",
       "4                  161                               9.55    13429   \n",
       "\n",
       "   Watch time (hours)  Sub­scribers  Your es­tim­ated rev­en­ue (USD)  ...  \\\n",
       "0          65850.7042         46453                          7959.533  ...   \n",
       "1            200.2966            -3                             6.113  ...   \n",
       "2           3687.3387           189                           202.963  ...   \n",
       "3           2148.3110          1917                           155.779  ...   \n",
       "4           1034.3945           150                            39.920  ...   \n",
       "\n",
       "   Im­pres­sions click-through rate (%)  Monday  Saturday  Sunday  Thursday  \\\n",
       "0                                  3.14       0         0       0         0   \n",
       "1                                  0.72       0         0       0         1   \n",
       "2                                  2.53       0         0       0         1   \n",
       "3                                  4.01       0         1       0         0   \n",
       "4                                  3.38       0         0       0         0   \n",
       "\n",
       "   Tuesday  Wednesday  DateScience?  Average_view_duration_(s)  \\\n",
       "0        0          0             1                        189   \n",
       "1        0          0             0                        314   \n",
       "2        0          0             0                        621   \n",
       "3        0          0             1                        156   \n",
       "4        0          1             0                        277   \n",
       "\n",
       "   Like_Dislike_Ratio  \n",
       "0               49.79  \n",
       "1               32.50  \n",
       "2               58.73  \n",
       "3              119.18  \n",
       "4               39.33  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform_video.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Video', 'Com­ments ad­ded', 'Shares', 'Sub­scribers lost',\n",
       "       'Sub­scribers gained', 'Av­er­age per­cent­age viewed (%)', 'Views',\n",
       "       'Watch time (hours)', 'Sub­scribers',\n",
       "       'Your es­tim­ated rev­en­ue (USD)', 'Im­pres­sions',\n",
       "       'Im­pres­sions click-through rate (%)', 'Monday', 'Saturday', 'Sunday',\n",
       "       'Thursday', 'Tuesday', 'Wednesday', 'DateScience?',\n",
       "       'Average_view_duration_(s)', 'Like_Dislike_Ratio'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform_video.columns"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
